{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee6c83f-bcf9-4922-ab98-c373452e38c3",
   "metadata": {},
   "source": [
    "<h1>Práctica de Laboratorio: Análisis de Emociones y Sentimiento</h1>\n",
    "<p><strong>Máster en Bioinformática y Biología Computacional</strong><br>\n",
    "<strong>Minería de Texto - Curso 2025-26</strong></p>\n",
    "\n",
    "<p><strong>Integrantes:</strong> [Gonzalo Santana, Tania] y [Parra Gutiérrez, Daniel]</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa136629-b813-4af7-8e72-52a439d4bcd1",
   "metadata": {},
   "source": [
    "En este ejercicio, trabajaremos con el Procesamiento del Lenguaje Natural (PLN) para analizar las emociones \n",
    "expresadas en textos literarios disponibles en Project Gutenberg. El objetivo es construir un sistema que pueda \n",
    "identificar y contar las emociones y sentimientos presentes en estas obras. Este ejercicio se enfoca en el uso de \n",
    "técnicas avanzadas de PLN, la extracción de información de texto y el procesamiento de lenguaje natural en \n",
    "general. \n",
    "\n",
    "Para llevar a cabo este ejercicio, se te proporcionará acceso a una serie de recursos y herramientas, incluyendo \n",
    "el léxico de emociones NRC (National Research Council), la base de datos léxica WordNet, y la biblioteca de \n",
    "Python Beautiful Soup. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803871a-b631-469d-86c3-4ef21701ce55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d69c107-5b26-439e-968e-e9f4b6346f1b",
   "metadata": {},
   "source": [
    "#### Configuración inicial\n",
    "En esta sección, importamos las bibliotecas necesarias y descargamos los recursos de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4351d7-0db5-4d23-8362-64746a610b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee00da74-8579-474b-aabb-50b8c221b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Tania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Tania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Tania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "# Descargar recursos de NLTK\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')  # recursos adicionales si hacen falta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "89249309-2686-4930-9313-5b0ba74d2ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "520a4184-ac11-4edf-9d52-17fabb6da48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tania\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Tania/nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[0;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEste es un ejemplo de tokenización.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m tokens \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokens)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    145\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m _get_punkt_tokenizer(language)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PunktTokenizer(language)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_lang(lang)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m find(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt_tab/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Tania/nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Este es un ejemplo de tokenización.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fdd3be-0cbb-4e18-81bf-0a567cf1ab27",
   "metadata": {},
   "source": [
    "**Tarea 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a05eac2-d319-4210-a39b-4717cec07818",
   "metadata": {},
   "source": [
    "(1.5 puntos) Cargar en una estructura de datos Python el Word-Emotion Association Lexicon del \n",
    "NRC5. Asegúrate de entender cómo se estructura el léxico y cómo se mapean las palabras a las \n",
    "emociones. Hay que tener en cuenta que existen varios ficheros con la misma información: un fichero \n",
    "con toda la información, un fichero por emoción, etc. Se puede elegir la opción que se estime oportuna. \n",
    "Se deberá considerar cómo organizar el léxico en memoria para un acceso rápido durante el análisis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df2551-7523-4d94-bc32-c906bd771212",
   "metadata": {},
   "source": [
    "##### Carga del léxico de emociones NRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f0c15-452e-47cd-bfb4-46a9161076a0",
   "metadata": {},
   "source": [
    "Vamos a cargar el léxico NRC. Supongamos que hemos descargado el archivo \"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\" desde el enlace proporcionado. Este archivo tiene el formato: palabra, emoción, asociación (1 o 0).\n",
    "\n",
    "Nota: Podemos descargar el archivo manualmente o por código."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7bfd5-2aa7-423f-834b-231afe1ece81",
   "metadata": {},
   "source": [
    "###### Descarga por código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6087bd40-6bda-4a60-ac6d-327392330014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo descargado y guardado como 'NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL directa del léxico NRC (puede cambiar, pero esta es la habitual)\n",
    "# url = \"https:/mmm/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "\n",
    "# Nombre del archivo local\n",
    "filename = \"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "\n",
    "# Descargar y guardar\n",
    "response = requests.get(url)\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "print(f\"Archivo descargado y guardado como '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71372602-da0a-4aa2-998f-c159982599ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad511367-a1f3-483a-a499-062c0f7b4601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abacus', ['trust']),\n",
       " ('abandon', ['fear', 'negative', 'sadness']),\n",
       " ('abandoned', ['anger', 'fear', 'negative', 'sadness']),\n",
       " ('abandonment', ['anger', 'fear', 'negative', 'sadness', 'surprise']),\n",
       " ('abba', ['positive']),\n",
       " ('abbot', ['trust']),\n",
       " ('abduction', ['fear', 'negative', 'sadness', 'surprise']),\n",
       " ('aberrant', ['negative']),\n",
       " ('aberration', ['disgust', 'negative']),\n",
       " ('abhor', ['anger', 'disgust', 'fear', 'negative'])]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el léxico NRC\n",
    "emolex_file = 'NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'\n",
    "emolex = {}\n",
    "\n",
    "with open(emolex_file, 'r') as f:\n",
    "    for line in f:\n",
    "        word, emotion, association = line.strip().split('\\t')\n",
    "        if association == '1':\n",
    "            if word not in emolex:\n",
    "                emolex[word] = []\n",
    "            emolex[word].append(emotion)\n",
    "\n",
    "# Mostrar algunas palabras y sus emociones\n",
    "list(emolex.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3cc064d2-e6de-488c-8f57-f4fba67c7a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emolex(file_path):\n",
    "    \"\"\"\n",
    "    Carga el léxico de emociones NRC desde un archivo\n",
    "    Retorna: dict con estructura {palabra: [emociones]}\n",
    "    \"\"\"\n",
    "    emolex = {}\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) == 3:\n",
    "                    word, emotion, value = parts\n",
    "                    if value == '1':\n",
    "                        if word not in emolex:\n",
    "                            emolex[word] = []\n",
    "                        emolex[word].append(emotion)\n",
    "        print(f\"EmoLex cargado: {len(emolex)} palabras\")\n",
    "        return emolex\n",
    "    except FileNotFoundError:\n",
    "        print(\"Archivo EmoLex no encontrado\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d97d84b2-883f-429f-a183-10118ba09d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmoLex cargado: 6453 palabras\n"
     ]
    }
   ],
   "source": [
    "emolex = load_emolex('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6e69566-5cae-47f0-93da-38320b8842bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_emolex(filepath):\n",
    "    # adapta si usas el fichero \"full\" o los ficheros por emoción\n",
    "    word_emotions = defaultdict(set)  # word -> set(emotions)\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if len(row) < 3: continue\n",
    "            word, emotion, association = row[0].strip(), row[1].strip(), row[2].strip()\n",
    "            if association == '1':\n",
    "                word_emotions[word].add(emotion)\n",
    "    return word_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a019728-5b06-4a1e-82ee-90e363af7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex = load_emolex('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b6b9f64-1d65-4af1-a790-303a0feeefdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'abacus': {'trust'},\n",
       "             'abandon': {'fear', 'negative', 'sadness'},\n",
       "             'abandoned': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'abandonment': {'anger',\n",
       "              'fear',\n",
       "              'negative',\n",
       "              'sadness',\n",
       "              'surprise'},\n",
       "             'abba': {'positive'},\n",
       "             'abbot': {'trust'},\n",
       "             'abduction': {'fear', 'negative', 'sadness', 'surprise'},\n",
       "             'aberrant': {'negative'},\n",
       "             'aberration': {'disgust', 'negative'},\n",
       "             'abhor': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'abhorrent': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'ability': {'positive'},\n",
       "             'abject': {'disgust', 'negative'},\n",
       "             'abnormal': {'disgust', 'negative'},\n",
       "             'abolish': {'anger', 'negative'},\n",
       "             'abolition': {'negative'},\n",
       "             'abominable': {'disgust', 'fear', 'negative'},\n",
       "             'abomination': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'abort': {'negative'},\n",
       "             'abortion': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'abortive': {'negative', 'sadness'},\n",
       "             'abovementioned': {'positive'},\n",
       "             'abrasion': {'negative'},\n",
       "             'abrogate': {'negative'},\n",
       "             'abrupt': {'surprise'},\n",
       "             'abscess': {'negative', 'sadness'},\n",
       "             'absence': {'fear', 'negative', 'sadness'},\n",
       "             'absent': {'negative', 'sadness'},\n",
       "             'absentee': {'negative', 'sadness'},\n",
       "             'absenteeism': {'negative'},\n",
       "             'absolute': {'positive'},\n",
       "             'absolution': {'joy', 'positive', 'trust'},\n",
       "             'absorbed': {'positive'},\n",
       "             'absurd': {'negative'},\n",
       "             'absurdity': {'negative'},\n",
       "             'abundance': {'anticipation',\n",
       "              'disgust',\n",
       "              'joy',\n",
       "              'negative',\n",
       "              'positive',\n",
       "              'trust'},\n",
       "             'abundant': {'joy', 'positive'},\n",
       "             'abuse': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'abysmal': {'negative', 'sadness'},\n",
       "             'abyss': {'fear', 'negative', 'sadness'},\n",
       "             'academic': {'positive', 'trust'},\n",
       "             'academy': {'positive'},\n",
       "             'accelerate': {'anticipation'},\n",
       "             'acceptable': {'positive'},\n",
       "             'acceptance': {'positive'},\n",
       "             'accessible': {'positive'},\n",
       "             'accident': {'fear', 'negative', 'sadness', 'surprise'},\n",
       "             'accidental': {'fear', 'negative', 'surprise'},\n",
       "             'accidentally': {'surprise'},\n",
       "             'accolade': {'anticipation',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'accommodation': {'positive'},\n",
       "             'accompaniment': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'accomplish': {'joy', 'positive'},\n",
       "             'accomplished': {'joy', 'positive'},\n",
       "             'accomplishment': {'positive'},\n",
       "             'accord': {'positive', 'trust'},\n",
       "             'account': {'trust'},\n",
       "             'accountability': {'positive', 'trust'},\n",
       "             'accountable': {'positive', 'trust'},\n",
       "             'accountant': {'trust'},\n",
       "             'accounts': {'trust'},\n",
       "             'accredited': {'positive', 'trust'},\n",
       "             'accueil': {'positive'},\n",
       "             'accurate': {'positive', 'trust'},\n",
       "             'accursed': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'accusation': {'anger', 'disgust', 'negative'},\n",
       "             'accusative': {'negative'},\n",
       "             'accused': {'anger', 'fear', 'negative'},\n",
       "             'accuser': {'anger', 'fear', 'negative'},\n",
       "             'accusing': {'anger', 'fear', 'negative'},\n",
       "             'ace': {'positive'},\n",
       "             'ache': {'negative', 'sadness'},\n",
       "             'achieve': {'joy', 'positive', 'trust'},\n",
       "             'achievement': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'aching': {'negative', 'sadness'},\n",
       "             'acid': {'negative'},\n",
       "             'acknowledgment': {'positive'},\n",
       "             'acquire': {'positive'},\n",
       "             'acquiring': {'anticipation', 'positive'},\n",
       "             'acrobat': {'fear', 'joy', 'positive', 'trust'},\n",
       "             'action': {'positive'},\n",
       "             'actionable': {'anger', 'disgust', 'negative'},\n",
       "             'actual': {'positive'},\n",
       "             'acuity': {'positive'},\n",
       "             'acumen': {'positive'},\n",
       "             'adapt': {'positive'},\n",
       "             'adaptable': {'positive'},\n",
       "             'adder': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'addiction': {'negative'},\n",
       "             'addresses': {'anticipation', 'positive'},\n",
       "             'adept': {'positive'},\n",
       "             'adequacy': {'positive'},\n",
       "             'adhering': {'trust'},\n",
       "             'adipose': {'negative'},\n",
       "             'adjudicate': {'fear', 'negative'},\n",
       "             'adjunct': {'positive'},\n",
       "             'administrative': {'trust'},\n",
       "             'admirable': {'joy', 'positive', 'trust'},\n",
       "             'admiral': {'positive', 'trust'},\n",
       "             'admiration': {'joy', 'positive', 'trust'},\n",
       "             'admire': {'positive', 'trust'},\n",
       "             'admirer': {'positive'},\n",
       "             'admissible': {'positive', 'trust'},\n",
       "             'admonition': {'fear', 'negative'},\n",
       "             'adorable': {'joy', 'positive'},\n",
       "             'adoration': {'joy', 'positive', 'trust'},\n",
       "             'adore': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'adrift': {'anticipation', 'fear', 'negative', 'sadness'},\n",
       "             'adulterated': {'negative'},\n",
       "             'adultery': {'disgust', 'negative', 'sadness'},\n",
       "             'advance': {'anticipation',\n",
       "              'fear',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise'},\n",
       "             'advanced': {'positive'},\n",
       "             'advancement': {'positive'},\n",
       "             'advantage': {'positive'},\n",
       "             'advantageous': {'positive'},\n",
       "             'advent': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'adventure': {'anticipation', 'positive'},\n",
       "             'adventurous': {'positive'},\n",
       "             'adversary': {'anger', 'negative'},\n",
       "             'adverse': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'adversity': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'advice': {'trust'},\n",
       "             'advisable': {'positive', 'trust'},\n",
       "             'advise': {'positive', 'trust'},\n",
       "             'advised': {'trust'},\n",
       "             'adviser': {'positive', 'trust'},\n",
       "             'advocacy': {'anger', 'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'advocate': {'trust'},\n",
       "             'aesthetic': {'positive'},\n",
       "             'aesthetics': {'joy', 'positive'},\n",
       "             'affable': {'positive'},\n",
       "             'affection': {'joy', 'positive', 'trust'},\n",
       "             'affiliated': {'positive'},\n",
       "             'affirm': {'positive', 'trust'},\n",
       "             'affirmation': {'positive'},\n",
       "             'affirmative': {'positive'},\n",
       "             'affirmatively': {'positive', 'trust'},\n",
       "             'afflict': {'fear', 'negative', 'sadness'},\n",
       "             'afflicted': {'negative'},\n",
       "             'affliction': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'affluence': {'joy', 'positive'},\n",
       "             'affluent': {'positive'},\n",
       "             'afford': {'positive'},\n",
       "             'affront': {'anger',\n",
       "              'disgust',\n",
       "              'fear',\n",
       "              'negative',\n",
       "              'sadness',\n",
       "              'surprise'},\n",
       "             'afraid': {'fear', 'negative'},\n",
       "             'aftermath': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'aftertaste': {'negative'},\n",
       "             'aga': {'fear', 'positive', 'trust'},\n",
       "             'aggravated': {'anger', 'negative'},\n",
       "             'aggravating': {'anger', 'negative', 'sadness'},\n",
       "             'aggravation': {'anger', 'disgust', 'negative'},\n",
       "             'aggression': {'anger', 'fear', 'negative'},\n",
       "             'aggressive': {'anger', 'fear', 'negative'},\n",
       "             'aggressor': {'anger', 'fear', 'negative'},\n",
       "             'aghast': {'disgust', 'fear', 'negative', 'surprise'},\n",
       "             'agile': {'positive'},\n",
       "             'agility': {'positive'},\n",
       "             'agitated': {'anger', 'negative'},\n",
       "             'agitation': {'anger', 'negative'},\n",
       "             'agonizing': {'fear', 'negative'},\n",
       "             'agony': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'agree': {'positive'},\n",
       "             'agreeable': {'positive', 'trust'},\n",
       "             'agreed': {'positive', 'trust'},\n",
       "             'agreeing': {'positive', 'trust'},\n",
       "             'agreement': {'positive', 'trust'},\n",
       "             'agriculture': {'positive'},\n",
       "             'aground': {'negative'},\n",
       "             'ahead': {'positive'},\n",
       "             'aid': {'positive'},\n",
       "             'aiding': {'positive'},\n",
       "             'ail': {'negative', 'sadness'},\n",
       "             'ailing': {'fear', 'negative', 'sadness'},\n",
       "             'aimless': {'negative'},\n",
       "             'airport': {'anticipation'},\n",
       "             'airs': {'disgust', 'negative'},\n",
       "             'akin': {'trust'},\n",
       "             'alabaster': {'positive'},\n",
       "             'alarm': {'fear', 'negative', 'surprise'},\n",
       "             'alarming': {'fear', 'negative', 'surprise'},\n",
       "             'alb': {'trust'},\n",
       "             'alcoholism': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'alertness': {'anticipation', 'fear', 'positive', 'surprise'},\n",
       "             'alerts': {'anticipation', 'fear', 'surprise'},\n",
       "             'alien': {'disgust', 'fear', 'negative'},\n",
       "             'alienate': {'anger', 'disgust', 'negative'},\n",
       "             'alienated': {'negative', 'sadness'},\n",
       "             'alienation': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'alimentation': {'positive'},\n",
       "             'alimony': {'negative'},\n",
       "             'alive': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'allay': {'positive'},\n",
       "             'allegation': {'anger', 'negative'},\n",
       "             'allege': {'negative'},\n",
       "             'allegiance': {'positive', 'trust'},\n",
       "             'allegro': {'positive'},\n",
       "             'alleviate': {'positive'},\n",
       "             'alleviation': {'positive'},\n",
       "             'alliance': {'trust'},\n",
       "             'allied': {'positive', 'trust'},\n",
       "             'allowable': {'positive'},\n",
       "             'allure': {'anticipation', 'joy', 'positive', 'surprise'},\n",
       "             'alluring': {'positive'},\n",
       "             'ally': {'positive', 'trust'},\n",
       "             'almighty': {'positive'},\n",
       "             'aloha': {'anticipation', 'joy', 'positive'},\n",
       "             'aloof': {'negative'},\n",
       "             'altercation': {'anger', 'negative'},\n",
       "             'amaze': {'surprise'},\n",
       "             'amazingly': {'joy', 'positive', 'surprise'},\n",
       "             'ambassador': {'positive', 'trust'},\n",
       "             'ambiguous': {'negative'},\n",
       "             'ambition': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'ambulance': {'fear', 'trust'},\n",
       "             'ambush': {'anger', 'fear', 'negative', 'surprise'},\n",
       "             'ameliorate': {'positive'},\n",
       "             'amen': {'joy', 'positive', 'trust'},\n",
       "             'amenable': {'positive'},\n",
       "             'amend': {'positive'},\n",
       "             'amends': {'positive'},\n",
       "             'amenity': {'positive'},\n",
       "             'amiable': {'positive'},\n",
       "             'amicable': {'joy', 'positive'},\n",
       "             'ammonia': {'disgust'},\n",
       "             'amnesia': {'negative'},\n",
       "             'amnesty': {'joy', 'positive'},\n",
       "             'amortization': {'trust'},\n",
       "             'amour': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'amphetamines': {'disgust', 'negative'},\n",
       "             'amuse': {'joy', 'positive'},\n",
       "             'amused': {'joy', 'positive'},\n",
       "             'amusement': {'joy', 'positive'},\n",
       "             'amusing': {'joy', 'positive'},\n",
       "             'anaconda': {'disgust', 'fear', 'negative'},\n",
       "             'anal': {'negative'},\n",
       "             'analyst': {'anticipation', 'positive', 'trust'},\n",
       "             'anarchism': {'anger', 'fear', 'negative'},\n",
       "             'anarchist': {'anger', 'fear', 'negative'},\n",
       "             'anarchy': {'anger', 'fear', 'negative'},\n",
       "             'anathema': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'ancestral': {'trust'},\n",
       "             'anchor': {'positive'},\n",
       "             'anchorage': {'positive', 'sadness'},\n",
       "             'ancient': {'negative'},\n",
       "             'angel': {'anticipation', 'joy', 'positive', 'surprise', 'trust'},\n",
       "             'angelic': {'joy', 'positive', 'trust'},\n",
       "             'anger': {'anger', 'negative'},\n",
       "             'angina': {'fear', 'negative'},\n",
       "             'angling': {'anticipation', 'negative'},\n",
       "             'angry': {'anger', 'disgust', 'negative'},\n",
       "             'anguish': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'animate': {'positive'},\n",
       "             'animated': {'joy', 'positive'},\n",
       "             'animosity': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'animus': {'anger', 'negative'},\n",
       "             'annihilate': {'anger', 'fear', 'negative'},\n",
       "             'annihilated': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'annihilation': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'announcement': {'anticipation'},\n",
       "             'annoy': {'anger', 'disgust', 'negative'},\n",
       "             'annoyance': {'anger', 'disgust', 'negative'},\n",
       "             'annoying': {'anger', 'negative'},\n",
       "             'annul': {'negative'},\n",
       "             'annulment': {'negative', 'sadness'},\n",
       "             'anomaly': {'fear', 'negative', 'surprise'},\n",
       "             'anonymous': {'negative'},\n",
       "             'answerable': {'trust'},\n",
       "             'antagonism': {'anger', 'negative'},\n",
       "             'antagonist': {'anger', 'negative'},\n",
       "             'antagonistic': {'anger', 'disgust', 'negative'},\n",
       "             'anthrax': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'antibiotics': {'positive'},\n",
       "             'antichrist': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'anticipation': {'anticipation'},\n",
       "             'anticipatory': {'anticipation'},\n",
       "             'antidote': {'anticipation', 'positive', 'trust'},\n",
       "             'antifungal': {'positive', 'trust'},\n",
       "             'antipathy': {'anger', 'disgust', 'negative'},\n",
       "             'antiquated': {'negative'},\n",
       "             'antique': {'positive'},\n",
       "             'antiseptic': {'positive', 'trust'},\n",
       "             'antisocial': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'antithesis': {'anger', 'negative'},\n",
       "             'anxiety': {'anger',\n",
       "              'anticipation',\n",
       "              'fear',\n",
       "              'negative',\n",
       "              'sadness'},\n",
       "             'anxious': {'anticipation', 'fear', 'negative'},\n",
       "             'apache': {'fear', 'negative'},\n",
       "             'apathetic': {'negative', 'sadness'},\n",
       "             'apathy': {'negative', 'sadness'},\n",
       "             'aphid': {'disgust', 'negative'},\n",
       "             'aplomb': {'positive'},\n",
       "             'apologetic': {'positive', 'trust'},\n",
       "             'apologize': {'positive', 'sadness', 'trust'},\n",
       "             'apology': {'positive'},\n",
       "             'apostle': {'positive', 'trust'},\n",
       "             'apostolic': {'trust'},\n",
       "             'appalling': {'disgust', 'fear', 'negative'},\n",
       "             'apparition': {'fear', 'surprise'},\n",
       "             'appeal': {'anticipation'},\n",
       "             'appendicitis': {'fear', 'negative', 'sadness'},\n",
       "             'applause': {'joy', 'positive', 'surprise', 'trust'},\n",
       "             'applicant': {'anticipation'},\n",
       "             'appreciation': {'joy', 'positive', 'trust'},\n",
       "             'apprehend': {'fear'},\n",
       "             'apprehension': {'fear', 'negative'},\n",
       "             'apprehensive': {'anticipation', 'fear', 'negative'},\n",
       "             'apprentice': {'trust'},\n",
       "             'approaching': {'anticipation'},\n",
       "             'approbation': {'positive', 'trust'},\n",
       "             'appropriation': {'negative'},\n",
       "             'approval': {'positive'},\n",
       "             'approve': {'joy', 'positive', 'trust'},\n",
       "             'approving': {'positive'},\n",
       "             'apt': {'positive'},\n",
       "             'aptitude': {'positive'},\n",
       "             'arbiter': {'trust'},\n",
       "             'arbitration': {'anticipation'},\n",
       "             'arbitrator': {'trust'},\n",
       "             'archaeology': {'anticipation', 'positive'},\n",
       "             'archaic': {'negative'},\n",
       "             'architecture': {'trust'},\n",
       "             'ardent': {'anticipation', 'joy', 'positive'},\n",
       "             'ardor': {'positive'},\n",
       "             'arduous': {'negative'},\n",
       "             'argue': {'anger', 'negative'},\n",
       "             'argument': {'anger', 'negative'},\n",
       "             'argumentation': {'anger'},\n",
       "             'argumentative': {'negative'},\n",
       "             'arguments': {'anger'},\n",
       "             'arid': {'negative', 'sadness'},\n",
       "             'aristocracy': {'positive'},\n",
       "             'aristocratic': {'positive'},\n",
       "             'armament': {'anger', 'fear'},\n",
       "             'armaments': {'fear', 'negative'},\n",
       "             'armed': {'anger', 'fear', 'negative', 'positive'},\n",
       "             'armor': {'fear', 'positive', 'trust'},\n",
       "             'armored': {'fear'},\n",
       "             'armory': {'trust'},\n",
       "             'aroma': {'positive'},\n",
       "             'arouse': {'anticipation', 'positive'},\n",
       "             'arraignment': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'array': {'positive'},\n",
       "             'arrears': {'negative'},\n",
       "             'arrest': {'negative'},\n",
       "             'arrival': {'anticipation'},\n",
       "             'arrive': {'anticipation'},\n",
       "             'arrogance': {'negative'},\n",
       "             'arrogant': {'anger', 'disgust', 'negative'},\n",
       "             'arsenic': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'arson': {'anger', 'fear', 'negative'},\n",
       "             'art': {'anticipation', 'joy', 'positive', 'sadness', 'surprise'},\n",
       "             'articulate': {'positive'},\n",
       "             'articulation': {'positive'},\n",
       "             'artillery': {'fear', 'negative'},\n",
       "             'artisan': {'positive'},\n",
       "             'artiste': {'positive'},\n",
       "             'artistic': {'positive'},\n",
       "             'ascendancy': {'positive'},\n",
       "             'ascent': {'positive'},\n",
       "             'ash': {'negative'},\n",
       "             'ashamed': {'disgust', 'negative', 'sadness'},\n",
       "             'ashes': {'negative', 'sadness'},\n",
       "             'asp': {'fear'},\n",
       "             'aspiration': {'anticipation',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'aspire': {'anticipation', 'joy', 'positive'},\n",
       "             'aspiring': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'ass': {'negative'},\n",
       "             'assail': {'anger', 'fear', 'negative', 'surprise'},\n",
       "             'assailant': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'assassin': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'assassinate': {'anger', 'fear', 'negative'},\n",
       "             'assassination': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'assault': {'anger', 'fear', 'negative'},\n",
       "             'assembly': {'positive', 'trust'},\n",
       "             'assent': {'positive'},\n",
       "             'asserting': {'positive', 'trust'},\n",
       "             'assessment': {'surprise', 'trust'},\n",
       "             'assessor': {'trust'},\n",
       "             'assets': {'positive'},\n",
       "             'asshole': {'anger', 'disgust', 'negative'},\n",
       "             'assignee': {'trust'},\n",
       "             'assist': {'positive', 'trust'},\n",
       "             'assistance': {'positive'},\n",
       "             'associate': {'positive', 'trust'},\n",
       "             'association': {'trust'},\n",
       "             'assuage': {'positive'},\n",
       "             'assurance': {'positive', 'trust'},\n",
       "             'assure': {'trust'},\n",
       "             'assured': {'positive', 'trust'},\n",
       "             'assuredly': {'trust'},\n",
       "             'astonishingly': {'positive', 'surprise'},\n",
       "             'astonishment': {'joy', 'positive', 'surprise'},\n",
       "             'astray': {'fear', 'negative'},\n",
       "             'astringent': {'negative'},\n",
       "             'astrologer': {'anticipation', 'positive'},\n",
       "             'astronaut': {'positive'},\n",
       "             'astronomer': {'anticipation', 'positive'},\n",
       "             'astute': {'positive'},\n",
       "             'asylum': {'fear', 'negative'},\n",
       "             'asymmetry': {'disgust'},\n",
       "             'atheism': {'negative'},\n",
       "             'atherosclerosis': {'fear', 'negative', 'sadness'},\n",
       "             'athlete': {'positive'},\n",
       "             'athletic': {'positive'},\n",
       "             'atom': {'positive'},\n",
       "             'atone': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'atonement': {'positive'},\n",
       "             'atrocious': {'anger', 'disgust', 'negative'},\n",
       "             'atrocity': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'atrophy': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'attachment': {'positive'},\n",
       "             'attack': {'anger', 'fear', 'negative'},\n",
       "             'attacking': {'anger',\n",
       "              'disgust',\n",
       "              'fear',\n",
       "              'negative',\n",
       "              'sadness',\n",
       "              'surprise'},\n",
       "             'attainable': {'anticipation', 'positive'},\n",
       "             'attainment': {'positive'},\n",
       "             'attempt': {'anticipation'},\n",
       "             'attendance': {'anticipation'},\n",
       "             'attendant': {'positive', 'trust'},\n",
       "             'attention': {'positive'},\n",
       "             'attentive': {'positive', 'trust'},\n",
       "             'attenuated': {'negative'},\n",
       "             'attenuation': {'negative', 'sadness'},\n",
       "             'attest': {'positive', 'trust'},\n",
       "             'attestation': {'trust'},\n",
       "             'attorney': {'anger', 'fear', 'positive', 'trust'},\n",
       "             'attraction': {'positive'},\n",
       "             'attractiveness': {'positive'},\n",
       "             'auction': {'anticipation'},\n",
       "             'audacity': {'negative'},\n",
       "             'audience': {'anticipation'},\n",
       "             'auditor': {'fear', 'trust'},\n",
       "             'augment': {'positive'},\n",
       "             'august': {'positive'},\n",
       "             'aunt': {'positive', 'trust'},\n",
       "             'aura': {'positive'},\n",
       "             'auspicious': {'anticipation', 'joy', 'positive'},\n",
       "             'austere': {'fear', 'negative', 'sadness'},\n",
       "             'austerity': {'negative'},\n",
       "             'authentic': {'joy', 'positive', 'trust'},\n",
       "             'authenticate': {'trust'},\n",
       "             'authentication': {'trust'},\n",
       "             'authenticity': {'positive', 'trust'},\n",
       "             'author': {'positive', 'trust'},\n",
       "             'authoritative': {'positive', 'trust'},\n",
       "             'authority': {'positive', 'trust'},\n",
       "             'authorization': {'positive', 'trust'},\n",
       "             'authorize': {'trust'},\n",
       "             'authorized': {'positive'},\n",
       "             'autocratic': {'negative'},\n",
       "             'automatic': {'trust'},\n",
       "             'autopsy': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'avalanche': {'fear', 'negative', 'sadness', 'surprise'},\n",
       "             'avarice': {'anger', 'disgust', 'negative'},\n",
       "             'avatar': {'positive'},\n",
       "             'avenger': {'anger', 'negative'},\n",
       "             'averse': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'aversion': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'avoid': {'fear', 'negative'},\n",
       "             'avoidance': {'fear', 'negative'},\n",
       "             'avoiding': {'fear'},\n",
       "             'await': {'anticipation'},\n",
       "             'award': {'anticipation', 'joy', 'positive', 'surprise', 'trust'},\n",
       "             'awful': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'awkwardness': {'disgust', 'negative'},\n",
       "             'awry': {'negative'},\n",
       "             'axiom': {'trust'},\n",
       "             'axiomatic': {'trust'},\n",
       "             'ay': {'positive'},\n",
       "             'aye': {'positive'},\n",
       "             'babble': {'negative'},\n",
       "             'babbling': {'negative'},\n",
       "             'baboon': {'disgust', 'negative'},\n",
       "             'baby': {'joy', 'positive'},\n",
       "             'babysitter': {'trust'},\n",
       "             'baccalaureate': {'positive'},\n",
       "             'backbone': {'anger', 'positive', 'trust'},\n",
       "             'backer': {'trust'},\n",
       "             'backward': {'negative'},\n",
       "             'backwards': {'disgust', 'negative'},\n",
       "             'backwater': {'negative', 'sadness'},\n",
       "             'bacteria': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'bacterium': {'disgust', 'fear', 'negative'},\n",
       "             'bad': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'badge': {'trust'},\n",
       "             'badger': {'anger', 'negative'},\n",
       "             'badly': {'negative', 'sadness'},\n",
       "             'badness': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'bailiff': {'fear', 'negative', 'trust'},\n",
       "             'bait': {'fear', 'negative', 'trust'},\n",
       "             'balance': {'positive'},\n",
       "             'balanced': {'positive'},\n",
       "             'bale': {'fear', 'negative'},\n",
       "             'balk': {'negative'},\n",
       "             'ballad': {'positive'},\n",
       "             'ballet': {'positive'},\n",
       "             'ballot': {'anticipation', 'positive', 'trust'},\n",
       "             'balm': {'anticipation', 'joy', 'negative', 'positive'},\n",
       "             'balsam': {'positive'},\n",
       "             'ban': {'negative'},\n",
       "             'bandit': {'negative'},\n",
       "             'bane': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'bang': {'anger',\n",
       "              'disgust',\n",
       "              'fear',\n",
       "              'negative',\n",
       "              'sadness',\n",
       "              'surprise'},\n",
       "             'banger': {'anger',\n",
       "              'anticipation',\n",
       "              'fear',\n",
       "              'negative',\n",
       "              'surprise'},\n",
       "             'banish': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'banished': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'banishment': {'anger', 'disgust', 'negative', 'sadness'},\n",
       "             'bank': {'trust'},\n",
       "             'banker': {'trust'},\n",
       "             'bankrupt': {'fear', 'negative', 'sadness'},\n",
       "             'bankruptcy': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'banquet': {'anticipation', 'joy', 'positive'},\n",
       "             'banshee': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'baptism': {'positive'},\n",
       "             'baptismal': {'joy', 'positive'},\n",
       "             'barb': {'anger', 'negative'},\n",
       "             'barbarian': {'fear', 'negative'},\n",
       "             'barbaric': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'barbarism': {'negative'},\n",
       "             'bard': {'positive'},\n",
       "             'barf': {'disgust'},\n",
       "             'bargain': {'positive', 'trust'},\n",
       "             'bark': {'anger', 'negative'},\n",
       "             'barred': {'negative'},\n",
       "             'barren': {'negative', 'sadness'},\n",
       "             'barricade': {'fear', 'negative'},\n",
       "             'barrier': {'anger', 'negative'},\n",
       "             'barrow': {'disgust'},\n",
       "             'bartender': {'trust'},\n",
       "             'barter': {'trust'},\n",
       "             'base': {'trust'},\n",
       "             'baseless': {'negative'},\n",
       "             'basketball': {'anticipation', 'joy', 'positive'},\n",
       "             'bastard': {'disgust', 'negative', 'sadness'},\n",
       "             'bastion': {'anger', 'positive'},\n",
       "             'bath': {'positive'},\n",
       "             'battalion': {'anger'},\n",
       "             'batter': {'anger', 'fear', 'negative'},\n",
       "             'battered': {'fear', 'negative', 'sadness'},\n",
       "             'battery': {'anger', 'negative'},\n",
       "             'battle': {'anger', 'negative'},\n",
       "             'battled': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'battlefield': {'fear', 'negative'},\n",
       "             'bawdy': {'negative'},\n",
       "             'bayonet': {'anger', 'fear', 'negative'},\n",
       "             'beach': {'joy'},\n",
       "             'beam': {'joy', 'positive'},\n",
       "             'beaming': {'anticipation', 'joy', 'positive'},\n",
       "             'bear': {'anger', 'fear'},\n",
       "             'bearer': {'negative'},\n",
       "             'bearish': {'anger', 'fear'},\n",
       "             'beast': {'anger', 'fear', 'negative'},\n",
       "             'beastly': {'disgust', 'fear', 'negative'},\n",
       "             'beating': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'beautification': {'joy', 'positive', 'trust'},\n",
       "             'beautiful': {'joy', 'positive'},\n",
       "             'beautify': {'joy', 'positive'},\n",
       "             'beauty': {'joy', 'positive'},\n",
       "             'bedrock': {'positive', 'trust'},\n",
       "             'bee': {'anger', 'fear'},\n",
       "             'beer': {'joy', 'positive'},\n",
       "             'befall': {'negative'},\n",
       "             'befitting': {'positive'},\n",
       "             'befriend': {'joy', 'positive', 'trust'},\n",
       "             'beg': {'negative', 'sadness'},\n",
       "             'beggar': {'negative', 'sadness'},\n",
       "             'begging': {'negative'},\n",
       "             'begun': {'anticipation'},\n",
       "             'behemoth': {'fear', 'negative'},\n",
       "             'beholden': {'negative'},\n",
       "             'belated': {'negative'},\n",
       "             'believed': {'trust'},\n",
       "             'believer': {'trust'},\n",
       "             'believing': {'positive', 'trust'},\n",
       "             'belittle': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'belligerent': {'anger', 'fear', 'negative'},\n",
       "             'bellows': {'anger'},\n",
       "             'belt': {'anger', 'fear', 'negative'},\n",
       "             'bender': {'negative'},\n",
       "             'benefactor': {'positive', 'trust'},\n",
       "             'beneficial': {'positive'},\n",
       "             'benefit': {'positive'},\n",
       "             'benevolence': {'joy', 'positive', 'trust'},\n",
       "             'benign': {'joy', 'positive'},\n",
       "             'bequest': {'trust'},\n",
       "             'bereaved': {'negative', 'sadness'},\n",
       "             'bereavement': {'negative', 'sadness'},\n",
       "             'bereft': {'negative'},\n",
       "             'berserk': {'anger', 'negative'},\n",
       "             'berth': {'positive'},\n",
       "             'bestial': {'disgust', 'fear', 'negative'},\n",
       "             'betray': {'anger', 'disgust', 'negative', 'sadness', 'surprise'},\n",
       "             'betrayal': {'anger', 'disgust', 'negative', 'sadness'},\n",
       "             'betrothed': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'betterment': {'positive'},\n",
       "             'beverage': {'positive'},\n",
       "             'beware': {'anticipation', 'fear', 'negative'},\n",
       "             'bewildered': {'fear', 'negative', 'surprise'},\n",
       "             'bewilderment': {'fear', 'surprise'},\n",
       "             'bias': {'anger', 'negative'},\n",
       "             'biased': {'negative'},\n",
       "             'biblical': {'positive'},\n",
       "             'bickering': {'anger', 'disgust', 'negative'},\n",
       "             'biennial': {'anticipation'},\n",
       "             'bier': {'fear', 'negative', 'sadness'},\n",
       "             'bigot': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'bigoted': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'bile': {'anger', 'disgust', 'negative'},\n",
       "             'bilingual': {'positive'},\n",
       "             'biopsy': {'fear', 'negative'},\n",
       "             'birch': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'birth': {'anticipation', 'fear', 'joy', 'positive', 'trust'},\n",
       "             'birthday': {'anticipation', 'joy', 'positive', 'surprise'},\n",
       "             'birthplace': {'anger', 'negative'},\n",
       "             'bitch': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'bite': {'negative'},\n",
       "             'bitterly': {'anger', 'disgust', 'negative', 'sadness'},\n",
       "             'bitterness': {'anger', 'disgust', 'negative', 'sadness'},\n",
       "             'bizarre': {'negative', 'surprise'},\n",
       "             'blackjack': {'negative'},\n",
       "             'blackmail': {'anger', 'fear', 'negative'},\n",
       "             'blackness': {'fear', 'negative', 'sadness'},\n",
       "             'blame': {'anger', 'disgust', 'negative'},\n",
       "             'blameless': {'positive'},\n",
       "             'bland': {'negative'},\n",
       "             'blanket': {'trust'},\n",
       "             'blasphemous': {'anger', 'disgust', 'negative'},\n",
       "             'blasphemy': {'anger', 'negative'},\n",
       "             'blast': {'anger', 'fear', 'negative', 'surprise'},\n",
       "             'blatant': {'anger', 'disgust', 'negative'},\n",
       "             'blather': {'negative'},\n",
       "             'blaze': {'anger', 'negative'},\n",
       "             'bleak': {'negative', 'sadness'},\n",
       "             'bleeding': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'blemish': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'bless': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'blessed': {'joy', 'positive'},\n",
       "             'blessing': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'blessings': {'anticipation',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'blight': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'blighted': {'disgust', 'negative', 'sadness'},\n",
       "             'blinded': {'negative'},\n",
       "             'blindfold': {'anticipation', 'fear', 'surprise'},\n",
       "             'blindly': {'negative', 'sadness'},\n",
       "             'blindness': {'negative', 'sadness'},\n",
       "             'bliss': {'joy', 'positive'},\n",
       "             'blissful': {'joy', 'positive'},\n",
       "             'blister': {'disgust', 'negative'},\n",
       "             'blitz': {'surprise'},\n",
       "             'bloated': {'disgust', 'negative'},\n",
       "             'blob': {'disgust', 'fear', 'negative'},\n",
       "             'blockade': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'bloodless': {'positive'},\n",
       "             'bloodshed': {'anger',\n",
       "              'disgust',\n",
       "              'fear',\n",
       "              'negative',\n",
       "              'sadness',\n",
       "              'surprise'},\n",
       "             'bloodthirsty': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'bloody': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'bloom': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'blossom': {'joy', 'positive'},\n",
       "             'blot': {'negative'},\n",
       "             'blower': {'negative'},\n",
       "             'blowout': {'negative'},\n",
       "             'blue': {'sadness'},\n",
       "             'blues': {'fear', 'negative', 'sadness'},\n",
       "             'bluff': {'negative'},\n",
       "             'blunder': {'disgust', 'negative', 'sadness'},\n",
       "             'blur': {'negative'},\n",
       "             'blurred': {'negative'},\n",
       "             'blush': {'negative'},\n",
       "             'board': {'anticipation'},\n",
       "             'boast': {'negative', 'positive'},\n",
       "             'boasting': {'negative'},\n",
       "             'bodyguard': {'positive', 'trust'},\n",
       "             'bog': {'negative'},\n",
       "             'bogus': {'anger', 'disgust', 'negative'},\n",
       "             'boil': {'disgust', 'negative'},\n",
       "             'boilerplate': {'negative'},\n",
       "             'boisterous': {'anger',\n",
       "              'anticipation',\n",
       "              'joy',\n",
       "              'negative',\n",
       "              'positive'},\n",
       "             'bold': {'positive'},\n",
       "             'boldness': {'positive'},\n",
       "             'bolster': {'positive'},\n",
       "             'bomb': {'anger', 'fear', 'negative', 'sadness', 'surprise'},\n",
       "             'bombard': {'anger', 'fear', 'negative'},\n",
       "             'bombardment': {'anger', 'fear', 'negative'},\n",
       "             'bombed': {'disgust', 'negative'},\n",
       "             'bomber': {'fear', 'sadness'},\n",
       "             'bonanza': {'joy', 'positive'},\n",
       "             'bondage': {'fear', 'negative', 'sadness'},\n",
       "             'bonds': {'negative'},\n",
       "             'bonne': {'positive'},\n",
       "             'bonus': {'anticipation', 'joy', 'positive', 'surprise'},\n",
       "             'boo': {'negative'},\n",
       "             'booby': {'negative'},\n",
       "             'bookish': {'positive'},\n",
       "             'bookshop': {'positive'},\n",
       "             'bookworm': {'negative', 'positive'},\n",
       "             'boomerang': {'anticipation', 'trust'},\n",
       "             'boon': {'positive'},\n",
       "             'booze': {'negative'},\n",
       "             'bore': {'negative'},\n",
       "             'boredom': {'negative', 'sadness'},\n",
       "             'boring': {'negative'},\n",
       "             'borrower': {'negative'},\n",
       "             'bother': {'negative'},\n",
       "             'bothering': {'anger', 'negative', 'sadness'},\n",
       "             'bottom': {'negative', 'sadness'},\n",
       "             'bottomless': {'fear'},\n",
       "             'bound': {'negative'},\n",
       "             'bountiful': {'anticipation', 'joy', 'positive'},\n",
       "             'bounty': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'bouquet': {'joy', 'positive', 'trust'},\n",
       "             'bout': {'anger', 'negative'},\n",
       "             'bovine': {'disgust', 'negative'},\n",
       "             'bowels': {'disgust'},\n",
       "             'boxing': {'anger'},\n",
       "             'boycott': {'negative'},\n",
       "             'brag': {'negative'},\n",
       "             'brains': {'positive'},\n",
       "             'bran': {'disgust'},\n",
       "             'brandy': {'negative'},\n",
       "             'bravado': {'negative'},\n",
       "             'bravery': {'positive'},\n",
       "             'brawl': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'brazen': {'anger', 'negative'},\n",
       "             'breach': {'negative'},\n",
       "             'break': {'surprise'},\n",
       "             'breakdown': {'negative'},\n",
       "             'breakfast': {'positive'},\n",
       "             'breakneck': {'negative'},\n",
       "             'breakup': {'negative', 'sadness'},\n",
       "             'bribe': {'negative'},\n",
       "             'bribery': {'disgust', 'negative'},\n",
       "             'bridal': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'bride': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'bridegroom': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'bridesmaid': {'joy', 'positive', 'trust'},\n",
       "             'brigade': {'fear', 'negative'},\n",
       "             'brighten': {'joy', 'positive', 'surprise', 'trust'},\n",
       "             'brightness': {'positive'},\n",
       "             'brilliant': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'brimstone': {'anger', 'fear', 'negative'},\n",
       "             'bristle': {'negative'},\n",
       "             'broadside': {'anticipation', 'negative'},\n",
       "             'brocade': {'positive'},\n",
       "             'broil': {'anger', 'negative'},\n",
       "             'broke': {'fear', 'negative', 'sadness'},\n",
       "             'broken': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'brothel': {'disgust', 'negative'},\n",
       "             'brother': {'positive', 'trust'},\n",
       "             'brotherhood': {'positive', 'trust'},\n",
       "             'brotherly': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'bruise': {'anticipation', 'negative'},\n",
       "             'brunt': {'anger', 'negative'},\n",
       "             'brutal': {'anger', 'fear', 'negative'},\n",
       "             'brutality': {'anger', 'fear', 'negative'},\n",
       "             'brute': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'buck': {'fear', 'negative', 'positive', 'surprise'},\n",
       "             'buddy': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'budget': {'trust'},\n",
       "             'buffet': {'anger', 'negative'},\n",
       "             'bug': {'disgust', 'fear', 'negative'},\n",
       "             'bugaboo': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'bugle': {'anticipation'},\n",
       "             'build': {'positive'},\n",
       "             'building': {'positive'},\n",
       "             'bulbous': {'negative'},\n",
       "             'bulldog': {'positive'},\n",
       "             'bulletproof': {'positive'},\n",
       "             'bully': {'anger', 'fear', 'negative'},\n",
       "             'bum': {'disgust', 'negative', 'sadness'},\n",
       "             'bummer': {'anger', 'disgust', 'negative'},\n",
       "             'bunker': {'fear'},\n",
       "             'buoy': {'positive'},\n",
       "             'burdensome': {'fear', 'negative', 'sadness'},\n",
       "             'bureaucracy': {'negative', 'trust'},\n",
       "             'bureaucrat': {'disgust', 'negative'},\n",
       "             'burglar': {'disgust', 'fear', 'negative'},\n",
       "             'burglary': {'negative'},\n",
       "             'burial': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'buried': {'fear', 'negative', 'sadness'},\n",
       "             'burke': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'burlesque': {'surprise'},\n",
       "             'burnt': {'disgust', 'negative'},\n",
       "             'bursary': {'trust'},\n",
       "             'bury': {'sadness'},\n",
       "             'buss': {'joy', 'positive'},\n",
       "             'busted': {'anger', 'fear', 'negative'},\n",
       "             'butcher': {'anger', 'disgust', 'fear', 'negative'},\n",
       "             'butler': {'positive', 'trust'},\n",
       "             'butt': {'negative'},\n",
       "             'buttery': {'positive'},\n",
       "             'buxom': {'positive'},\n",
       "             'buzz': {'anticipation', 'fear', 'positive'},\n",
       "             'buzzed': {'negative'},\n",
       "             'bye': {'anticipation'},\n",
       "             'bylaw': {'trust'},\n",
       "             'cab': {'positive'},\n",
       "             'cabal': {'fear', 'negative'},\n",
       "             'cabinet': {'positive', 'trust'},\n",
       "             'cable': {'surprise'},\n",
       "             'cacophony': {'anger', 'disgust', 'negative'},\n",
       "             'cad': {'anger', 'disgust', 'negative'},\n",
       "             'cadaver': {'disgust', 'fear', 'negative', 'sadness', 'surprise'},\n",
       "             'cafe': {'positive'},\n",
       "             'cage': {'negative', 'sadness'},\n",
       "             'calamity': {'sadness'},\n",
       "             'calculating': {'negative'},\n",
       "             'calculation': {'anticipation'},\n",
       "             'calculator': {'positive', 'trust'},\n",
       "             'calf': {'joy', 'positive', 'trust'},\n",
       "             'callous': {'anger', 'disgust', 'negative'},\n",
       "             'calls': {'anticipation', 'negative', 'trust'},\n",
       "             'calm': {'positive'},\n",
       "             'camouflage': {'surprise'},\n",
       "             'camouflaged': {'surprise'},\n",
       "             'campaigning': {'anger', 'fear', 'negative'},\n",
       "             'canary': {'positive'},\n",
       "             'cancel': {'negative', 'sadness'},\n",
       "             'cancer': {'anger', 'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'candid': {'anticipation',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'candidate': {'positive'},\n",
       "             'candied': {'positive'},\n",
       "             'cane': {'anger', 'fear'},\n",
       "             'canker': {'anger', 'disgust', 'negative'},\n",
       "             'cannibal': {'disgust', 'fear', 'negative'},\n",
       "             'cannibalism': {'disgust', 'negative'},\n",
       "             'cannon': {'anger', 'fear', 'negative'},\n",
       "             'canons': {'trust'},\n",
       "             'cap': {'anticipation', 'trust'},\n",
       "             'capitalist': {'positive'},\n",
       "             'captain': {'positive'},\n",
       "             'captivate': {'anticipation',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'captivating': {'positive'},\n",
       "             'captive': {'fear', 'negative', 'sadness'},\n",
       "             'captivity': {'negative', 'sadness'},\n",
       "             'captor': {'fear', 'negative'},\n",
       "             'capture': {'negative'},\n",
       "             'carcass': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'carcinoma': {'fear', 'negative', 'sadness'},\n",
       "             'cardiomyopathy': {'fear', 'negative', 'sadness'},\n",
       "             'career': {'anticipation', 'positive'},\n",
       "             'careful': {'positive'},\n",
       "             'carefully': {'positive'},\n",
       "             'carelessness': {'anger', 'disgust', 'negative'},\n",
       "             'caress': {'positive'},\n",
       "             'caretaker': {'positive', 'trust'},\n",
       "             'caricature': {'negative'},\n",
       "             'caries': {'disgust', 'negative'},\n",
       "             'carnage': {'anger',\n",
       "              'disgust',\n",
       "              'fear',\n",
       "              'negative',\n",
       "              'sadness',\n",
       "              'surprise'},\n",
       "             'carnal': {'negative'},\n",
       "             'carnivorous': {'fear', 'negative'},\n",
       "             'carol': {'joy', 'positive', 'trust'},\n",
       "             'cartel': {'negative'},\n",
       "             'cartridge': {'fear'},\n",
       "             'cascade': {'positive'},\n",
       "             'case': {'fear', 'negative', 'sadness'},\n",
       "             'cash': {'anger',\n",
       "              'anticipation',\n",
       "              'fear',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'trust'},\n",
       "             'cashier': {'trust'},\n",
       "             'casket': {'fear', 'negative', 'sadness'},\n",
       "             'caste': {'negative'},\n",
       "             'casualty': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'cataract': {'anticipation', 'fear', 'negative', 'sadness'},\n",
       "             'catastrophe': {'anger',\n",
       "              'disgust',\n",
       "              'fear',\n",
       "              'negative',\n",
       "              'sadness',\n",
       "              'surprise'},\n",
       "             'catch': {'surprise'},\n",
       "             'catechism': {'disgust'},\n",
       "             'categorical': {'positive'},\n",
       "             'cater': {'positive'},\n",
       "             'cathartic': {'positive'},\n",
       "             'cathedral': {'joy', 'positive', 'trust'},\n",
       "             'catheter': {'negative'},\n",
       "             'caution': {'anger', 'anticipation', 'fear', 'negative'},\n",
       "             'cautionary': {'fear'},\n",
       "             'cautious': {'anticipation', 'fear', 'positive', 'trust'},\n",
       "             'cautiously': {'fear', 'positive'},\n",
       "             'cede': {'negative'},\n",
       "             'celebrated': {'anticipation', 'joy', 'positive'},\n",
       "             'celebrating': {'anticipation', 'joy', 'positive'},\n",
       "             'celebration': {'anticipation',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'celebrity': {'anger',\n",
       "              'anticipation',\n",
       "              'disgust',\n",
       "              'joy',\n",
       "              'negative',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'celestial': {'anticipation', 'joy', 'positive'},\n",
       "             'cement': {'anticipation', 'trust'},\n",
       "             'cemetery': {'fear', 'negative', 'sadness'},\n",
       "             'censor': {'anger', 'disgust', 'fear', 'negative', 'trust'},\n",
       "             'censure': {'negative'},\n",
       "             'center': {'positive', 'trust'},\n",
       "             'centurion': {'positive'},\n",
       "             'cerebral': {'positive'},\n",
       "             'ceremony': {'joy', 'positive', 'surprise'},\n",
       "             'certainty': {'positive'},\n",
       "             'certify': {'trust'},\n",
       "             'cess': {'disgust', 'negative'},\n",
       "             'cessation': {'negative'},\n",
       "             'chaff': {'anger', 'fear', 'negative'},\n",
       "             'chafing': {'negative'},\n",
       "             'chagrin': {'disgust', 'negative', 'sadness'},\n",
       "             'chairman': {'positive', 'trust'},\n",
       "             'chairwoman': {'positive', 'trust'},\n",
       "             'challenge': {'anger', 'fear', 'negative'},\n",
       "             'champion': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'chance': {'surprise'},\n",
       "             'chancellor': {'trust'},\n",
       "             'change': {'fear'},\n",
       "             'changeable': {'anticipation', 'surprise'},\n",
       "             'chant': {'anger', 'anticipation', 'joy', 'positive', 'surprise'},\n",
       "             'chaos': {'anger', 'fear', 'negative', 'sadness'},\n",
       "             'chaotic': {'anger', 'negative'},\n",
       "             'chaplain': {'trust'},\n",
       "             'charade': {'negative'},\n",
       "             'chargeable': {'fear', 'negative', 'sadness'},\n",
       "             'charger': {'positive'},\n",
       "             'charitable': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'charity': {'joy', 'positive'},\n",
       "             'charm': {'positive'},\n",
       "             'charmed': {'joy', 'negative', 'positive'},\n",
       "             'charming': {'positive'},\n",
       "             'chart': {'trust'},\n",
       "             'chase': {'negative'},\n",
       "             'chasm': {'fear'},\n",
       "             'chastisement': {'negative'},\n",
       "             'chastity': {'anticipation', 'positive', 'trust'},\n",
       "             'chattering': {'positive'},\n",
       "             'chatty': {'negative'},\n",
       "             'cheap': {'negative'},\n",
       "             'cheat': {'anger', 'disgust', 'negative'},\n",
       "             'checklist': {'positive', 'trust'},\n",
       "             'cheer': {'anticipation', 'joy', 'positive', 'surprise', 'trust'},\n",
       "             'cheerful': {'joy', 'positive', 'surprise'},\n",
       "             'cheerfulness': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'cheering': {'joy', 'positive'},\n",
       "             'cheery': {'anticipation', 'joy', 'positive'},\n",
       "             'cheesecake': {'negative'},\n",
       "             'chemist': {'positive', 'trust'},\n",
       "             'cherish': {'anticipation',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'cherry': {'positive'},\n",
       "             'chicane': {'anticipation', 'negative', 'surprise', 'trust'},\n",
       "             'chicken': {'fear'},\n",
       "             'chieftain': {'positive'},\n",
       "             'child': {'anticipation', 'joy', 'positive'},\n",
       "             'childhood': {'joy', 'positive'},\n",
       "             'childish': {'negative'},\n",
       "             'chilly': {'negative'},\n",
       "             'chimera': {'fear', 'surprise'},\n",
       "             'chirp': {'joy', 'positive'},\n",
       "             'chisel': {'positive'},\n",
       "             'chivalry': {'positive'},\n",
       "             'chloroform': {'negative'},\n",
       "             'chocolate': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'choice': {'positive'},\n",
       "             'choir': {'joy', 'positive', 'trust'},\n",
       "             'choke': {'anger', 'negative', 'sadness'},\n",
       "             'cholera': {'disgust', 'fear', 'negative', 'sadness'},\n",
       "             'chop': {'negative'},\n",
       "             'choral': {'joy', 'positive'},\n",
       "             'chore': {'negative'},\n",
       "             'chorus': {'positive'},\n",
       "             'chosen': {'positive'},\n",
       "             'chowder': {'positive'},\n",
       "             'chronic': {'negative', 'sadness'},\n",
       "             'chronicle': {'positive', 'trust'},\n",
       "             'chuckle': {'anticipation',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'church': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'cider': {'positive'},\n",
       "             'cigarette': {'negative'},\n",
       "             'circumcision': {'positive'},\n",
       "             'circumvention': {'negative', 'positive'},\n",
       "             'citizen': {'positive'},\n",
       "             'civil': {'positive'},\n",
       "             'civility': {'positive'},\n",
       "             'civilization': {'positive', 'trust'},\n",
       "             'civilized': {'joy', 'positive', 'trust'},\n",
       "             'claimant': {'anger', 'disgust'},\n",
       "             'clairvoyant': {'positive'},\n",
       "             'clamor': {'anger',\n",
       "              'anticipation',\n",
       "              'disgust',\n",
       "              'negative',\n",
       "              'surprise'},\n",
       "             'clan': {'trust'},\n",
       "             'clap': {'anticipation', 'joy', 'positive', 'trust'},\n",
       "             'clarify': {'positive'},\n",
       "             'clash': {'anger', 'negative'},\n",
       "             'clashing': {'anger', 'fear', 'negative'},\n",
       "             'classic': {'positive'},\n",
       "             'classical': {'positive'},\n",
       "             'classics': {'joy', 'positive'},\n",
       "             'classify': {'positive'},\n",
       "             'claw': {'anger', 'fear', 'negative'},\n",
       "             'clean': {'joy', 'positive', 'trust'},\n",
       "             'cleaning': {'positive'},\n",
       "             'cleanliness': {'positive'},\n",
       "             'cleanly': {'positive'},\n",
       "             'cleanse': {'positive'},\n",
       "             'cleansing': {'positive'},\n",
       "             'clearance': {'positive', 'trust'},\n",
       "             'clearness': {'positive'},\n",
       "             'cleave': {'fear'},\n",
       "             'clerical': {'positive', 'trust'},\n",
       "             'clever': {'positive'},\n",
       "             'cleverness': {'positive'},\n",
       "             'cliff': {'fear'},\n",
       "             'climax': {'anticipation',\n",
       "              'joy',\n",
       "              'positive',\n",
       "              'surprise',\n",
       "              'trust'},\n",
       "             'clock': {'anticipation'},\n",
       "             'cloister': {'negative'},\n",
       "             'closeness': {'joy', 'positive', 'trust'},\n",
       "             'closure': {'anticipation', 'joy', 'positive', 'sadness'},\n",
       "             'clothe': {'positive'},\n",
       "             'clouded': {'negative', 'sadness'},\n",
       "             ...})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emolex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187392d9-fed3-49e9-b2ed-3e2ee058a409",
   "metadata": {},
   "source": [
    "#### Extensión del léxico usando WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab796c-ade9-4d5d-9ea5-98c13567db66",
   "metadata": {},
   "source": [
    "Vamos a extender el léxico NRC añadiendo sinónimos, hipónimos, hiperónimos y formas derivadas de las palabras originales. Usaremos WordNet y la función derivationally_related_forms().\n",
    "\n",
    "Además, usaremos los diccionarios de mapeo de POS-tags proporcionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "278f7a7d-cfcc-4a99-9284-58341de5fd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del léxico extendido: 61842\n"
     ]
    }
   ],
   "source": [
    "# Diccionarios para mapeo de POS-tags\n",
    "wordnet_to_penn = {\n",
    "    'n': 'NN',  # sustantivo\n",
    "    'v': 'VB',  # verbo\n",
    "    'a': 'JJ',  # adjetivo\n",
    "    's': 'JJ',  # adjetivo superlativo\n",
    "    'r': 'RB',  # adverbio\n",
    "    'c': 'CC'   # conjunción\n",
    "}\n",
    "\n",
    "penn_to_wordnet = {\n",
    "    'CC': 'c',   # Coordinating conjunction\n",
    "    'CD': 'c',   # Cardinal number\n",
    "    'DT': 'c',   # Determiner\n",
    "    'EX': 'c',   # Existential there\n",
    "    'FW': 'x',   # Foreign word\n",
    "    'IN': 'c',   # Preposition or subordinating conjunction\n",
    "    'JJ': 'a',   # Adjective\n",
    "    'JJR': 'a',  # Adjective, comparative\n",
    "    'JJS': 'a',  # Adjective, superlative\n",
    "    'LS': 'c',   # List item marker\n",
    "    'MD': 'v',   # Modal\n",
    "    'NN': 'n',   # Noun, singular or mass\n",
    "    'NNS': 'n',  # Noun, plural\n",
    "    'NNP': 'n',  # Proper noun, singular\n",
    "    'NNPS': 'n', # Proper noun, plural\n",
    "    'PDT': 'c',  # Predeterminer\n",
    "    'POS': 'c',  # Possessive ending\n",
    "    'PRP': 'n',  # Personal pronoun\n",
    "    'PRP$': 'n', # Possessive pronoun\n",
    "    'RB': 'r',   # Adverb\n",
    "    'RBR': 'r',  # Adverb, comparative\n",
    "    'RBS': 'r',  # Adverb, superlative\n",
    "    'RP': 'r',   # Particle\n",
    "    'SYM': 'x',  # Symbol\n",
    "    'TO': 'c',   # to\n",
    "    'UH': 'x',   # Interjection\n",
    "    'VB': 'v',   # Verb, base form\n",
    "    'VBD': 'v',  # Verb, past tense\n",
    "    'VBG': 'v',  # Verb, gerund or present participle\n",
    "    'VBN': 'v',  # Verb, past participle\n",
    "    'VBP': 'v',  # Verb, non-3rd person singular present\n",
    "    'VBZ': 'v',  # Verb, 3rd person singular present\n",
    "    'WDT': 'c',  # Wh-determiner\n",
    "    'WP': 'n',   # Wh-pronoun\n",
    "    'WP$': 'n',  # Possessive wh-pronoun\n",
    "    'WRB': 'r',  # Wh-adverb\n",
    "    'X': 'x'     # Any word not categorized by the other tags\n",
    "}\n",
    "\n",
    "# Inicializar el lematizador\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Crear un diccionario extendido\n",
    "extended_emolex = {}\n",
    "\n",
    "# Función para obtener sinónimos, hipónimos, hiperónimos y formas derivadas\n",
    "def get_wordnet_relations(word, pos_tag_wn):\n",
    "    synsets = wn.synsets(word, pos=pos_tag_wn)\n",
    "    relations = set()\n",
    "    for synset in synsets:\n",
    "        # Lemas del synset (sinónimos)\n",
    "        for lemma in synset.lemmas():\n",
    "            relations.add(lemma.name().replace('_', ' '))\n",
    "        # Hipónimos\n",
    "        for hypo in synset.hyponyms():\n",
    "            for lemma in hypo.lemmas():\n",
    "                relations.add(lemma.name().replace('_', ' '))\n",
    "        # Hiperónimos\n",
    "        for hyper in synset.hypernyms():\n",
    "            for lemma in hyper.lemmas():\n",
    "                relations.add(lemma.name().replace('_', ' '))\n",
    "        # Formas derivadas (derivationally_related_forms)\n",
    "        for lemma in synset.lemmas():\n",
    "            for related_form in lemma.derivationally_related_forms():\n",
    "                relations.add(related_form.name().replace('_', ' '))\n",
    "    return relations\n",
    "\n",
    "# Recorrer las palabras originales del EmoLex\n",
    "for word, emotions in emolex.items():\n",
    "    # Para cada palabra, intentar obtener su POS-tag usando WordNet\n",
    "    # Inicialmente, no sabemos el POS-tag, así que probaremos con los cuatro principales: n, v, a, r\n",
    "    for pos_wn in ['n', 'v', 'a', 'r']:\n",
    "        # Obtener relaciones\n",
    "        relations = get_wordnet_relations(word, pos_wn)\n",
    "        # Para cada palabra relacionada, agregar las emociones\n",
    "        for related_word in relations:\n",
    "            # Convertir el POS-tag de WordNet a Penn\n",
    "            pos_penn = wordnet_to_penn.get(pos_wn, None)\n",
    "            if pos_penn:\n",
    "                key = (related_word, pos_penn)\n",
    "                if key not in extended_emolex:\n",
    "                    extended_emolex[key] = set()\n",
    "                extended_emolex[key].update(emotions)\n",
    "\n",
    "    # También agregar la palabra original (sin POS-tag específico) pero necesitamos asignarle un POS-tag\n",
    "    # Para la palabra original, usaremos el primer POS-tag que encontremos en WordNet\n",
    "    synsets = wn.synsets(word)\n",
    "    if synsets:\n",
    "        pos_wn = synsets[0].pos()\n",
    "        pos_penn = wordnet_to_penn.get(pos_wn, None)\n",
    "        if pos_penn:\n",
    "            key = (word, pos_penn)\n",
    "            if key not in extended_emolex:\n",
    "                extended_emolex[key] = set()\n",
    "            extended_emolex[key].update(emotions)\n",
    "\n",
    "# Convertir los sets a listas para consistencia\n",
    "for key in extended_emolex:\n",
    "    extended_emolex[key] = list(extended_emolex[key])\n",
    "\n",
    "# Mostrar el tamaño del léxico extendido\n",
    "print(f\"Tamaño del léxico extendido: {len(extended_emolex)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "96665655-dfb1-4652-8693-ff247ee3939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_emolex(original_emolex):\n",
    "    \"\"\"\n",
    "    Extiende el léxico EmoLex usando WordNet\n",
    "    Retorna: dict con estructura {(lemma, pos_tag): [emociones]}\n",
    "    \"\"\"\n",
    "    extended_lexicon = {}\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for word, emotions in original_emolex.items():\n",
    "        # Probar diferentes POS tags para encontrar synsets\n",
    "        for pos in ['n', 'v', 'a', 'r']:\n",
    "            synsets = wn.synsets(word, pos=pos)\n",
    "            \n",
    "            for synset in synsets:\n",
    "                # Añadir lema principal\n",
    "                lemma = lemmatizer.lemmatize(word, pos=pos)\n",
    "                pos_tag_penn = wordnet_to_penn.get(pos, 'NN')\n",
    "                key = (lemma, pos_tag_penn)\n",
    "                \n",
    "                if key not in extended_lexicon:\n",
    "                    extended_lexicon[key] = set()\n",
    "                extended_lexicon[key].update(emotions)\n",
    "                \n",
    "                # Añadir sinónimos\n",
    "                for lemma_obj in synset.lemmas():\n",
    "                    synonym = lemma_obj.name().replace('_', ' ')\n",
    "                    synonym_key = (synonym, pos_tag_penn)\n",
    "                    if synonym_key not in extended_lexicon:\n",
    "                        extended_lexicon[synonym_key] = set()\n",
    "                    extended_lexicon[synonym_key].update(emotions)\n",
    "                \n",
    "                # Añadir hipónimos\n",
    "                for hyponym in synset.hyponyms():\n",
    "                    for lemma_obj in hyponym.lemmas():\n",
    "                        hyponym_word = lemma_obj.name().replace('_', ' ')\n",
    "                        hyponym_key = (hyponym_word, pos_tag_penn)\n",
    "                        if hyponym_key not in extended_lexicon:\n",
    "                            extended_lexicon[hyponym_key] = set()\n",
    "                        extended_lexicon[hyponym_key].update(emotions)\n",
    "                \n",
    "                # Añadir hiperónimos\n",
    "                for hypernym in synset.hypernyms():\n",
    "                    for lemma_obj in hypernym.lemmas():\n",
    "                        hypernym_word = lemma_obj.name().replace('_', ' ')\n",
    "                        hypernym_key = (hypernym_word, pos_tag_penn)\n",
    "                        if hypernym_key not in extended_lexicon:\n",
    "                            extended_lexicon[hypernym_key] = set()\n",
    "                        extended_lexicon[hypernym_key].update(emotions)\n",
    "    \n",
    "    # Convertir sets a listas\n",
    "    return {key: list(emotions) for key, emotions in extended_lexicon.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dbcf67f1-3c12-41aa-8eab-4b20d77f1b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Léxico extendido: 51100 entradas\n",
      "Ejemplo de entradas extendidas: {('abacus', 'NN'): ['trust', 'positive'], ('tablet', 'NN'): ['trust', 'positive'], ('calculator', 'NN'): ['disgust', 'trust', 'negative', 'fear', 'anger', 'positive', 'sadness'], ('calculating machine', 'NN'): ['disgust', 'trust', 'negative', 'fear', 'anger', 'positive', 'sadness'], ('abandon', 'NN'): ['negative', 'trust', 'fear', 'joy', 'anticipation', 'sadness', 'positive']}\n"
     ]
    }
   ],
   "source": [
    "# Extender el léxico\n",
    "extended_emolex = extend_emolex(emolex)\n",
    "print(f\"Léxico extendido: {len(extended_emolex)} entradas\")\n",
    "print(\"Ejemplo de entradas extendidas:\", dict(list(extended_emolex.items())[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d712239-be46-42b5-89eb-2c5539c2629b",
   "metadata": {},
   "source": [
    "#### Descarga de novelas de Project Gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e518f2-1cb8-49db-80bb-d083b8d14bb8",
   "metadata": {},
   "source": [
    "Usamos la función download_text proporcionada para descargar las novelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d5275fd4-27a1-4690-a6e5-586b28c8f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando Crime and Punishment...\n",
      "Crime and Punishment descargado correctamente.\n",
      "Descargando War and Peace...\n",
      "War and Peace descargado correctamente.\n",
      "Descargando Pride and Prejudice...\n",
      "Pride and Prejudice descargado correctamente.\n",
      "Descargando Frankenstein...\n",
      "Frankenstein descargado correctamente.\n",
      "Descargando The Adventures of Sherlock Holmes...\n",
      "The Adventures of Sherlock Holmes descargado correctamente.\n",
      "Descargando Ulysses...\n",
      "Ulysses descargado correctamente.\n",
      "Descargando The Odyssey...\n",
      "The Odyssey descargado correctamente.\n",
      "Descargando Moby Dick...\n",
      "Moby Dick descargado correctamente.\n",
      "Descargando The Divine Comedy...\n",
      "The Divine Comedy descargado correctamente.\n",
      "Descargando Critias...\n",
      "Critias descargado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Diccionario de libros\n",
    "books = {\n",
    "    'Crime and Punishment': 'http://www.gutenberg.org/files/2554/2554-0.txt',\n",
    "    'War and Peace': 'http://www.gutenberg.org/files/2600/2600-0.txt',\n",
    "    'Pride and Prejudice': 'http://www.gutenberg.org/files/1342/1342-0.txt',\n",
    "    'Frankenstein': 'https://www.gutenberg.org/cache/epub/84/pg84.txt',\n",
    "    'The Adventures of Sherlock Holmes': 'http://www.gutenberg.org/files/1661/1661-0.txt',\n",
    "    'Ulysses': 'http://www.gutenberg.org/files/4300/4300-0.txt',\n",
    "    'The Odyssey': 'https://www.gutenberg.org/cache/epub/1727/pg1727.txt',\n",
    "    'Moby Dick': 'http://www.gutenberg.org/files/15/15-0.txt',\n",
    "    'The Divine Comedy': 'https://www.gutenberg.org/cache/epub/8800/pg8800.txt',\n",
    "    'Critias': 'https://www.gutenberg.org/cache/epub/1571/pg1571.txt'\n",
    "}\n",
    "\n",
    "def download_text(url):\n",
    "    \"\"\"Descarga el texto de una novela desde Project Gutenberg\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error al descargar: {e}\")\n",
    "        return None\n",
    "        \n",
    "# Descargar todos los libros\n",
    "book_texts = {}\n",
    "for title, url in books.items():\n",
    "    print(f\"Descargando {title}...\")\n",
    "    text = download_text(url)\n",
    "    if text:\n",
    "        book_texts[title] = text\n",
    "        print(f\"{title} descargado correctamente.\")\n",
    "    else:\n",
    "        print(f\"Fallo en la descarga de {title}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44061dd-f7ff-44e5-be12-b2ae0374ba1d",
   "metadata": {},
   "source": [
    "#### Análisis de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b004445-7e2b-44f8-a6df-19f18c1dbaa0",
   "metadata": {},
   "source": [
    "Implementamos la función para analizar el texto y contar las emociones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "464b2a5e-7a17-4247-9268-4b7ed95c8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando Crime and Punishment...\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Tania/nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m title, text \u001b[38;5;129;01min\u001b[39;00m book_texts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalizando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m     results[title] \u001b[38;5;241m=\u001b[39m analyze_emotions(text, extended_emolex)\n",
      "Cell \u001b[1;32mIn[102], line 6\u001b[0m, in \u001b[0;36manalyze_emotions\u001b[1;34m(text, lexicon)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_emotions\u001b[39m(text, lexicon):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Tokenización\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# POS-tagging\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     pos_tags \u001b[38;5;241m=\u001b[39m pos_tag(tokens)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    145\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m _get_punkt_tokenizer(language)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PunktTokenizer(language)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_lang(lang)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m find(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt_tab/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Tania/nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Tania\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el lematizador\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def analyze_emotions(text, lexicon):\n",
    "    # Tokenización\n",
    "    tokens = word_tokenize(text)\n",
    "    # POS-tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    # Inicializar contador de emociones\n",
    "    emotion_counts = {}\n",
    "    # Procesar cada token\n",
    "    for word, pos_tag_pen in pos_tags:\n",
    "        # Convertir POS-tag de PennTreeBank a WordNet\n",
    "        pos_wn = penn_to_wordnet.get(pos_tag_pen, None)\n",
    "        if pos_wn is None:\n",
    "            continue\n",
    "        # Lematización\n",
    "        lemma = lemmatizer.lemmatize(word, pos=pos_wn)\n",
    "        # Buscar en el léxico extendido\n",
    "        key = (lemma, pos_tag_pen)\n",
    "        if key in lexicon:\n",
    "            emotions = lexicon[key]\n",
    "            for emotion in emotions:\n",
    "                emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "    return emotion_counts\n",
    "\n",
    "# Analizar cada libro\n",
    "results = {}\n",
    "for title, text in book_texts.items():\n",
    "    print(f\"Analizando {title}...\")\n",
    "    results[title] = analyze_emotions(text, extended_emolex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424c7f6-d9f8-4c03-aa80-46f66c6125ff",
   "metadata": {},
   "source": [
    "#### Presentación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afadcdd-023a-4fa6-bba8-a6ca745acf6e",
   "metadata": {},
   "source": [
    "Vamos a mostrar los resultados en forma de tabla y gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6508f50-1431-4ca3-a323-b387d27f268c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Graficar los resultados\u001b[39;00m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m df\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, stacked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmociones en novelas clásicas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrecuencia\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_core.py:1030\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   1028\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[1;32m-> 1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_backend\u001b[38;5;241m.\u001b[39mplot(data, kind\u001b[38;5;241m=\u001b[39mkind, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[0;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 71\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mgenerate()\n\u001b[0;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:499\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_plot_data()\n\u001b[0;32m    500\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfig\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_plot(fig)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:698\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;66;03m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_empty:\n\u001b[1;32m--> 698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno numeric data to plot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m numeric_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear un DataFrame con los resultados\n",
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "# Rellenar NaN con 0\n",
    "df = df.fillna(0)\n",
    "# Mostrar la tabla\n",
    "df\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.figure(figsize=(12, 8))\n",
    "df.plot(kind='bar', stacked=True, figsize=(12,8))\n",
    "plt.title('Emociones en novelas clásicas')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Novelas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa37ab5-a621-493d-bf81-5226723ca67f",
   "metadata": {},
   "source": [
    "#### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52fdb5-75d5-48df-b9d5-fab801e3f76c",
   "metadata": {},
   "source": [
    "En esta sección, comenta brevemente los resultados obtenidos.\n",
    "* ¿Qué emociones son las más frecuentes en general?\n",
    "* ¿Hay novelas que destacan por alguna emoción en particular?\n",
    "* ¿Qué limitaciones has encontrado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07d114-8056-49a9-987f-7201938e881f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915dd1e-686d-42f2-ae54-539fea01e1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004047f4-aecd-42b7-9e72-8bea7d4c56d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313466a1-5ec6-4d87-a821-e59ad13244aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
